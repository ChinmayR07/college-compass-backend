{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3adc9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('static/raw-data/institution_details.csv')\n",
    "\n",
    "# Filter the DataFrame to include only rows where \"Graduate offering (HD2021)\" is 1\n",
    "df = df[df['Graduate offering (HD2021)'] == 1]\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "df.to_csv('static/clean_dataset/graduate_school_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abcf0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned graduate school dataset\n",
    "grad_school_df = pd.read_csv('static/clean_dataset/graduate_school_records.csv')\n",
    "\n",
    "# Load the admission considerations dataset\n",
    "admission_considerations_df = pd.read_csv('static/raw-data/admission_considerations.csv')\n",
    "\n",
    "# Filter the admission considerations dataset to only include rows where \"UnitID\" matches a value in the cleaned graduate school dataset\n",
    "filtered_admission_considerations_df = admission_considerations_df[admission_considerations_df['UnitID'].isin(grad_school_df['UnitID'])]\n",
    "\n",
    "# Load the enrollment details dataset\n",
    "enrollment_details_df = pd.read_csv('static/raw-data/enrollment_details.csv')\n",
    "\n",
    "# Filter the enrollment details dataset to only include rows where \"UnitID\" matches a value in the cleaned graduate school dataset\n",
    "filtered_enrollment_details_df = enrollment_details_df[enrollment_details_df['UnitID'].isin(grad_school_df['UnitID'])]\n",
    "\n",
    "# Load the ethnicity details dataset\n",
    "ethnicity_details_df = pd.read_csv('static/raw-data/ethnicity_details.csv')\n",
    "\n",
    "# Filter the ethnicity details dataset to only include rows where \"UnitID\" matches a value in the cleaned graduate school dataset\n",
    "filtered_ethnicity_details_df = ethnicity_details_df[ethnicity_details_df['UnitID'].isin(grad_school_df['UnitID'])]\n",
    "\n",
    "# Load the tuition details dataset\n",
    "tuition_details_df = pd.read_csv('static/raw-data/tuition_details.csv')\n",
    "\n",
    "# Filter the tuition details dataset to only include rows where \"UnitID\" matches a value in the cleaned graduate school dataset\n",
    "filtered_tuition_details_df = tuition_details_df[tuition_details_df['UnitID'].isin(grad_school_df['UnitID'])]\n",
    "\n",
    "# Save the filtered datasets to new CSV files\n",
    "filtered_admission_considerations_df.to_csv('static/clean_dataset/filtered_admission_considerations.csv', index=False)\n",
    "filtered_enrollment_details_df.to_csv('static/clean_dataset/filtered_enrollment_details.csv', index=False)\n",
    "filtered_ethnicity_details_df.to_csv('static/clean_dataset/filtered_ethnicity_details.csv', index=False)\n",
    "filtered_tuition_details_df.to_csv('static/clean_dataset/filtered_tuition_details.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29882178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the filtered data from admission_considerations.csv\n",
    "admission_df = pd.read_csv(\"static/clean_dataset/filtered_admission_considerations.csv\")\n",
    "\n",
    "# read the filtered data from enrollment_details.csv\n",
    "enrollment_df = pd.read_csv(\"static/clean_dataset/filtered_enrollment_details.csv\")\n",
    "\n",
    "# read the filtered data from ethnicity_details.csv\n",
    "ethnicity_df = pd.read_csv(\"static/clean_dataset/filtered_ethnicity_details.csv\")\n",
    "\n",
    "# read the filtered data from tuition_details.csv\n",
    "tuition_df = pd.read_csv(\"static/clean_dataset/filtered_tuition_details.csv\")\n",
    "\n",
    "# read the filtered data from graduate_school_records.csv\n",
    "grad_school_df = pd.read_csv(\"static/clean_dataset/graduate_school_records.csv\")\n",
    "\n",
    "# merge the data from all the dataframes on the 'UnitID' column\n",
    "merged_df = pd.merge(admission_df, enrollment_df, on='UnitID')\n",
    "merged_df = pd.merge(merged_df, ethnicity_df, on='UnitID')\n",
    "merged_df = pd.merge(merged_df, tuition_df, on='UnitID', suffixes=('_tuition', '_merged'))\n",
    "merged_df = pd.merge(merged_df, grad_school_df, on='UnitID')\n",
    "\n",
    "# write the merged data to a new csv file\n",
    "merged_df.to_csv(\"static/clean_dataset/combined_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f77222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('static/clean_dataset/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711c2443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnitID                                  0\n",
       "Institution Name_x                      0\n",
       "Open admission policy (IC2021)         21\n",
       "Secondary school GPA (ADM2021)        725\n",
       "Secondary school rank (ADM2021)       725\n",
       "                                     ... \n",
       "ZIP code (HD2021)                       0\n",
       "Institutional category (HD2021)         0\n",
       "Highest level of offering (HD2021)      0\n",
       "Undergraduate offering (HD2021)         0\n",
       "Graduate offering (HD2021)              0\n",
       "Length: 366, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d7ddc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188502"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7b393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "admissions_df = pd.read_csv('static/clean_dataset/filtered_admission_considerations.csv')\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "column_missing_perc = admissions_df.isnull().sum() / len(admissions_df)\n",
    "\n",
    "# Calculate the means of columns containing numeric values\n",
    "numeric_columns = admissions_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns.remove('UnitID') # Exclude the 'UnitID' column\n",
    "column_means = admissions_df[numeric_columns].mean()\n",
    "\n",
    "# Fill missing values in columns containing less than or equal to 40% missing values\n",
    "for column_name in column_missing_perc.index:\n",
    "    if column_missing_perc[column_name] <= 0.4 and column_name in numeric_columns:\n",
    "        column_mean = column_means[column_name]\n",
    "        admissions_df[column_name].fillna(column_mean, inplace=True)\n",
    "\n",
    "# Write the cleaned data to a new file\n",
    "admissions_df.to_csv('static/clean_dataset/admission_considerations_filtered_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ab3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('static/clean_dataset/admission_considerations_filtered_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfbd9dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnitID                                                          0\n",
       "Institution Name                                                0\n",
       "Open admission policy (IC2021)                                  0\n",
       "Secondary school GPA (ADM2021)                                  0\n",
       "Secondary school rank (ADM2021)                                 0\n",
       "Secondary school record (ADM2021)                               0\n",
       "Completion of college-preparatory program (ADM2021)             0\n",
       "Recommendations (ADM2021)                                       0\n",
       "Formal demonstration of competencies (ADM2021)                  0\n",
       "Admission test scores (ADM2021)                                 0\n",
       "Other Test (Wonderlic  WISC-III  etc.) (ADM2021)                0\n",
       "TOEFL (Test of English as a Foreign Language (ADM2021)          0\n",
       "Open admission policy (IC2020)                                  0\n",
       "Secondary school GPA (ADM2020_RV)                               0\n",
       "Secondary school rank (ADM2020_RV)                              0\n",
       "Secondary school record (ADM2020_RV)                            0\n",
       "Completion of college-preparatory program (ADM2020_RV)          0\n",
       "Recommendations (ADM2020_RV)                                    0\n",
       "Formal demonstration of competencies (ADM2020_RV)               0\n",
       "Admission test scores (ADM2020_RV)                              0\n",
       "Other Test (Wonderlic  WISC-III  etc.) (ADM2020_RV)             0\n",
       "TOEFL (Test of English as a Foreign Language (ADM2020_RV)       0\n",
       "Open admission policy (IC2019)                                  0\n",
       "Secondary school GPA (ADM2019_RV)                               0\n",
       "Secondary school rank (ADM2019_RV)                              0\n",
       "Secondary school record (ADM2019_RV)                            0\n",
       "Completion of college-preparatory program (ADM2019_RV)          0\n",
       "Recommendations (ADM2019_RV)                                    0\n",
       "Formal demonstration of competencies (ADM2019_RV)               0\n",
       "Admission test scores (ADM2019_RV)                              0\n",
       "Other Test (Wonderlic  WISC-III  etc.) (ADM2019_RV)             0\n",
       "TOEFL (Test of English as a Foreign Language (ADM2019_RV)       0\n",
       "Open admission policy (IC2018)                                  0\n",
       "Secondary school GPA (ADM2018_RV)                               0\n",
       "Secondary school rank (ADM2018_RV)                              0\n",
       "Secondary school record (ADM2018_RV)                            0\n",
       "Completion of college-preparatory program (ADM2018_RV)          0\n",
       "Recommendations (ADM2018_RV)                                    0\n",
       "Formal demonstration of competencies (ADM2018_RV)               0\n",
       "Admission test scores (ADM2018_RV)                              0\n",
       "Other Test (Wonderlic  WISC-III  etc.) (ADM2018_RV)             0\n",
       "TOEFL (Test of English as a Foreign Language (ADM2018_RV)       0\n",
       "Open admission policy (IC2017)                                  0\n",
       "Secondary school GPA (ADM2017_RV)                               0\n",
       "Secondary school rank (ADM2017_RV)                              0\n",
       "Secondary school record (ADM2017_RV)                            0\n",
       "Completion of college-preparatory program (ADM2017_RV)          0\n",
       "Recommendations (ADM2017_RV)                                    0\n",
       "Formal demonstration of competencies (ADM2017_RV)               0\n",
       "Admission test scores (ADM2017_RV)                              0\n",
       "Other Test (Wonderlic  WISC-III  etc.) (ADM2017_RV)             0\n",
       "TOEFL (Test of English as a Foreign Language (ADM2017_RV)       0\n",
       "Unnamed: 52                                                  2143\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba47b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def fill_missing_values(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter Alabama colleges\n",
    "    alabama_colleges = df[df['state'] == 'AL']\n",
    "\n",
    "    # Helper function to calculate mean with standard deviation of 2\n",
    "    def mean_within_2_std(column):\n",
    "        mean = column.mean()\n",
    "        std = column.std()\n",
    "        return mean - (2 * std), mean + (2 * std)\n",
    "\n",
    "    # Helper function to calculate missing values based on the conditions\n",
    "    def calculate_missing_values(row):\n",
    "        men = row['applicants_men_2021']\n",
    "        women = row['applicants_women_2021']\n",
    "        total = row['applicants_total_2021']\n",
    "\n",
    "        if pd.isnull(men) and pd.isnull(women) and pd.isnull(total):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            women_min, women_max = mean_within_2_std(alabama_colleges['applicants_women'].dropna())\n",
    "            men_mean = (men_min + men_max) / 2\n",
    "            women_mean = (women_min + women_max) / 2\n",
    "            row['applicants_menstatic/'] = men_mean\n",
    "            row['applicants_women'] = women_mean\n",
    "            row['applicants_total_2021'] = men_mean + women_mean\n",
    "\n",
    "        elif pd.isnull(men) and pd.isnull(women):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            men_mean = (men_min + men_max) / 2\n",
    "            row['applicants_men_2021'] = men_mean\n",
    "            row['applicants_women_2021'] = total - men_mean\n",
    "\n",
    "        elif pd.isnull(total):\n",
    "            total_min, total_max = mean_within_2_std(alabama_colleges['applicants_total_2021'].dropna())\n",
    "            total_mean = (total_min + total_max) / 2\n",
    "            if pd.isnull(men):\n",
    "                row['applicants_men_2021'] = total_mean - women\n",
    "            else:\n",
    "                row['applicants_women_2021'] = total_mean - men\n",
    "            row['applicants_total_2021'] = total_mean\n",
    "\n",
    "        elif pd.isnull(men):\n",
    "            row['applicants_men_2021'] = total - women\n",
    "\n",
    "        elif pd.isnull(women):\n",
    "            row['applicants_women_2021'] = total - men\n",
    "\n",
    "        return row\n",
    "\n",
    "    # Apply the helper function to fill missing values\n",
    "    df = df.apply(calculate_missing_values, axis=1)\n",
    "\n",
    "    # Save the filled DataFrame to a new CSV file\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df.to_csv(f\"filled_college_data_{current_time}.csv\", index=False)\n",
    "\n",
    "# Usage example\n",
    "file_path = \"C:\\\\College_Compass_backend\\\\college-compass-backend-flask\\\\static\\\\with_missing_values\\\\combined_with_lat_long.csv\"\n",
    "fill_missing_values(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d682d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if one of the three columns is missing\n",
    "        if row.isnull().sum() == 1:\n",
    "            if pd.isnull(row['applicants_total_2021']):\n",
    "                df.at[index, 'applicants_total_2021'] = row['applicants_men_2021'] + row['applicants_women_2021']\n",
    "            elif pd.isnull(row['applicants_men_2021']):\n",
    "                df.at[index, 'applicants_men_2021'] = row['applicants_total_2021'] - row['applicants_women_2021']\n",
    "            else:\n",
    "                df.at[index, 'applicants_women_2021'] = row['applicants_total_2021'] - row['applicants_men_2021']\n",
    "        \n",
    "        # Check if two of the three columns are missing\n",
    "        elif row.isnull().sum() == 2:\n",
    "            alabama_df = df[df['state'] == 'AL']\n",
    "            \n",
    "            if pd.isnull(row['applicants_total_2021']):\n",
    "                mean_men = alabama_df['applicants_men_2021'].mean()\n",
    "                mean_women = alabama_df['applicants_women_2021'].mean()\n",
    "                total_applicants = mean_men + mean_women\n",
    "                \n",
    "                if pd.isnull(row['applicants_men_2021']):\n",
    "                    df.at[index, 'applicants_total_2021'] = total_applicants\n",
    "                    df.at[index, 'applicants_men_2021'] = mean_men\n",
    "                else:\n",
    "                    df.at[index, 'applicants_total_2021'] = total_applicants\n",
    "                    df.at[index, 'applicants_women_2021'] = mean_women\n",
    "                    \n",
    "            else:\n",
    "                mean_total = alabama_df['applicants_total_2021'].mean()\n",
    "                if pd.isnull(row['applicants_men_2021']):\n",
    "                    df.at[index, 'applicants_men_2021'] = mean_total - row['applicants_women_2021']\n",
    "                else:\n",
    "                    df.at[index, 'applicants_women_2021'] = mean_total - row['applicants_men_2021']\n",
    "                \n",
    "        # Check if all three columns are missing\n",
    "        elif row.isnull().sum() == 3:\n",
    "            alabama_df = df[df['state'] == 'AL']\n",
    "            mean_men = alabama_df['applicants_men_2021'].mean()\n",
    "            mean_women = alabama_df['applicants_women_2021'].mean()\n",
    "            \n",
    "            df.at[index, 'applicants_men_2021'] = mean_men\n",
    "            df.at[index, 'applicants_women_2021'] = mean_women\n",
    "            df.at[index, 'applicants_total_2021'] = mean_men + mean_women\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\\\College_Compass_backend\\\\college-compass-backend-flask\\\\static\\\\with_missing_values\\\\combined_with_lat_long.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "filled_df = fill_missing_values(df)\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filled_df.to_csv(f\"filled_college_data_{current_time}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b057bbe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'randint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m     69\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCollege_Compass_backend\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcollege-compass-backend-flask\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwith_missing_values\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcombined_with_lat_long.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mfill_missing_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 59\u001b[0m, in \u001b[0;36mfill_missing_values\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Apply the helper function to fill missing values\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_missing_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Update Alabama colleges DataFrame\u001b[39;00m\n\u001b[0;32m     62\u001b[0m alabama_colleges \u001b[38;5;241m=\u001b[39m filter_alabama_colleges(df)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m, in \u001b[0;36mfill_missing_values.<locals>.calculate_missing_values\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     27\u001b[0m men_min, men_max \u001b[38;5;241m=\u001b[39m mean_within_2_std(alabama_colleges[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplicants_men_2021\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna())\n\u001b[0;32m     28\u001b[0m women_min, women_max \u001b[38;5;241m=\u001b[39m mean_within_2_std(alabama_colleges[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplicants_women_2021\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna())\n\u001b[1;32m---> 29\u001b[0m men_mean \u001b[38;5;241m=\u001b[39m \u001b[43mrandint\u001b[49m(men_min, men_max)\n\u001b[0;32m     30\u001b[0m women_mean \u001b[38;5;241m=\u001b[39m randint(women_min, women_max)\n\u001b[0;32m     31\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplicants_men_2021\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m men_mean\n",
      "\u001b[1;31mNameError\u001b[0m: name 'randint' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def fill_missing_values(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter Alabama colleges\n",
    "    def filter_alabama_colleges(df):\n",
    "        return df[df['state'] == 'AL']\n",
    "\n",
    "    alabama_colleges = filter_alabama_colleges(df)\n",
    "\n",
    "    # Helper function to calculate mean with standard deviation of 2\n",
    "    def mean_within_2_std(column):\n",
    "        mean = column.mean()\n",
    "        std = column.std()\n",
    "        return mean - (std), mean + (std)\n",
    "\n",
    "    # Helper function to calculate missing values based on the conditions\n",
    "    def calculate_missing_values(row):\n",
    "        men = row['applicants_men_2021']\n",
    "        women = row['applicants_women_2021']\n",
    "        total = row['applicants_total_2021']\n",
    "\n",
    "        if pd.isnull(men) and pd.isnull(women) and pd.isnull(total):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            women_min, women_max = mean_within_2_std(alabama_colleges['applicants_women_2021'].dropna())\n",
    "            men_mean = randint(men_min, men_max)\n",
    "            women_mean = randint(women_min, women_max)\n",
    "            row['applicants_men_2021'] = men_mean\n",
    "            row['applicants_women_2021'] = women_mean\n",
    "            row['applicants_total_2021'] = men_mean + women_mean\n",
    "\n",
    "        elif pd.isnull(men) and pd.isnull(women):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            men_mean = randint(men_min, men_max)\n",
    "            row['applicants_men_2021'] = men_mean\n",
    "            row['applicants_women_2021'] = total - men_mean\n",
    "\n",
    "        elif pd.isnull(total):\n",
    "            total_min, total_max = mean_within_2_std(alabama_colleges['applicants_total_2021'].dropna())\n",
    "            total_mean = randint(total_min, total_max)\n",
    "            if pd.isnull(men):\n",
    "                row['applicants_men_2021'] = total_mean - women\n",
    "            else:\n",
    "                row['applicants_women_2021'] = total_mean - men\n",
    "            row['applicants_total_2021'] = total_mean\n",
    "\n",
    "        elif pd.isnull(men):\n",
    "            row['applicants_men_2021'] = total - women\n",
    "\n",
    "        elif pd.isnull(women):\n",
    "            row['applicants_women_2021'] = total - men\n",
    "\n",
    "        return row\n",
    "\n",
    "    # Apply the helper function to fill missing values\n",
    "    df = df.apply(calculate_missing_values, axis=1)\n",
    "\n",
    "    # Update Alabama colleges DataFrame\n",
    "    alabama_colleges = filter_alabama_colleges(df)\n",
    "\n",
    "    # Save the filled DataFrame to a new CSV file\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df.to_csv(f\"filled_college_data_{current_time}.csv\", index=False)\n",
    "\n",
    "# Usage example\n",
    "file_path = \"C:\\\\College_Compass_backend\\\\college-compass-backend-flask\\\\static\\\\with_missing_values\\\\combined_with_lat_long.csv\"\n",
    "fill_missing_values(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45532f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "You can only assign a scalar value not a <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'slice(None, None, None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4210\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[1;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[0;32m   4209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4210\u001b[0m     icol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4211\u001b[0m     iindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m     \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m     \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: slice(None, None, None)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m     65\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCollege_Compass_backend\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcollege-compass-backend-flask\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwith_missing_values\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcombined_with_lat_long.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mfill_missing_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 58\u001b[0m, in \u001b[0;36mfill_missing_values\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Apply the helper function to fill missing values\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[index] \u001b[38;5;241m=\u001b[39m calculate_missing_values(row, filter_alabama_colleges(df))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Save the filled DataFrame to a new CSV file\u001b[39;00m\n\u001b[0;32m     61\u001b[0m current_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2442\u001b[0m, in \u001b[0;36m_AtIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   2440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 2442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2397\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m   2395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2397\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4230\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[1;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[0;32m   4225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_cache\u001b[38;5;241m.\u001b[39mpop(col, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m ii_err:\n\u001b[0;32m   4228\u001b[0m     \u001b[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m     \u001b[38;5;66;03m# row when only scalar options are permitted\u001b[39;00m\n\u001b[1;32m-> 4230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\n\u001b[0;32m   4231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can only assign a scalar value not a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4232\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mii_err\u001b[39;00m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: You can only assign a scalar value not a <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def fill_missing_values(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter Alabama colleges\n",
    "    def filter_alabama_colleges(df):\n",
    "        return df[df['state'] == 'AL']\n",
    "\n",
    "    # Helper function to calculate mean with standard deviation of 2\n",
    "    def mean_within_2_std(column):\n",
    "        mean = column.mean()\n",
    "        std = column.std()\n",
    "        return mean - (2 * std), mean + (2 * std)\n",
    "\n",
    "    # Helper function to calculate missing values based on the conditions\n",
    "    def calculate_missing_values(row, alabama_colleges):\n",
    "        men = row['applicants_men_2021']\n",
    "        women = row['applicants_women_2021']\n",
    "        total = row['applicants_total_2021']\n",
    "\n",
    "        if pd.isnull(men) and pd.isnull(women) and pd.isnull(total):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            women_min, women_max = mean_within_2_std(alabama_colleges['applicants_women_2021'].dropna())\n",
    "            men_mean = (men_min + men_max) / 2\n",
    "            women_mean = (women_min + women_max) / 2\n",
    "            row['applicants_men_2021'] = men_mean\n",
    "            row['applicants_women_2021'] = women_mean\n",
    "            row['applicants_total_2021'] = men_mean + women_mean\n",
    "\n",
    "        elif pd.isnull(men) and pd.isnull(women):\n",
    "            men_min, men_max = mean_within_2_std(alabama_colleges['applicants_men_2021'].dropna())\n",
    "            men_mean = (men_min + men_max) / 2\n",
    "            row['applicants_men_2021'] = men_mean\n",
    "            row['applicants_women_2021'] = total - men_mean\n",
    "\n",
    "        elif pd.isnull(total):\n",
    "            total_min, total_max = mean_within_2_std(alabama_colleges['applicants_total_2021'].dropna())\n",
    "            total_mean = (total_min + total_max) / 2\n",
    "            if pd.isnull(men):\n",
    "                row['applicants_men_2021'] = total_mean - women\n",
    "            else:\n",
    "                row['applicants_women_2021'] = total_mean - men\n",
    "            row['applicants_total_2021'] = total_mean\n",
    "\n",
    "        elif pd.isnull(men):\n",
    "            row['applicants_men_2021'] = total - women\n",
    "\n",
    "        elif pd.isnull(women):\n",
    "            row['applicants_women_2021'] = total - men\n",
    "\n",
    "        return row\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Apply the helper function to fill missing values\n",
    "        df.at[index] = calculate_missing_values(row, filter_alabama_colleges(df))\n",
    "\n",
    "    # Save the filled DataFrame to a new CSV file\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df.to_csv(f\"filled_college_data_{current_time}.csv\", index=False)\n",
    "\n",
    "# Usage example\n",
    "file_path = \"C:\\\\College_Compass_backend\\\\college-compass-backend-flask\\\\static\\\\with_missing_values\\\\combined_with_lat_long.csv\"\n",
    "fill_missing_values(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ec4ca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['applicants_men_2021', 'applicants_women_2021', 'applicants_total_2021']\n",
      "['admissions_men_2021', 'admission_women_2021', 'admissions_total_2021']\n",
      "['enrolled_ft_men_total_2021', 'enrolled_ft_women_total_2021', 'enrolled_ft_total_2021']\n",
      "['enrolled_pt_men_total_2021', 'enrolled_pt_women_total_2021', 'enrolled_pt_total_2021']\n",
      "['grand_total_men_2021', 'grand_total_women_2021', 'grand_total_2021']\n",
      "['am_ind_alaska_total_men_2021', 'am_ind_alaska_total_women_2021', 'am_ind_alaska_total_2021']\n",
      "['asian_men_2021', 'asian_women_2021', 'asian_total_2021']\n",
      "['bl_af_men_2021', 'bl_af_women_2021', 'bl_af_total_2021']\n",
      "['hisp_men_2021', 'hisp_women_2021', 'hisp_total_2021']\n",
      "['haw_pac_men_2021', 'haw_pac_women_2021', 'haw_pac_total_2021']\n",
      "['white_men_2021', 'white_women_2021', 'white_total_2021']\n",
      "['two_plus_race_men_2021', 'two_plus_race_women_2021', 'two_plus_race_total_2021']\n",
      "['unk_men_2021', 'unk_women_2021', 'unk_total_2021']\n",
      "['alien_men_2021', 'alien_women_2021', 'alien_total_2021']\n",
      "['applicants_men_2020', 'applicants_women_2020', 'applicants_total_2020']\n",
      "['admissions_men_2020', 'admission_women_2020', 'admissions_total_2020']\n",
      "['enrolled_ft_men_total_2020', 'enrolled_ft_women_total_2020', 'enrolled_ft_total_2020']\n",
      "['enrolled_pt_men_total_2020', 'enrolled_pt_women_total_2020', 'enrolled_pt_total_2020']\n",
      "['grand_total_men_2020', 'grand_total_women_2020', 'grand_total_2020']\n",
      "['am_ind_alaska_total_men_2020', 'am_ind_alaska_total_women_2020', 'am_ind_alaska_total_2020']\n",
      "['asian_men_2020', 'asian_women_2020', 'asian_total_2020']\n",
      "['bl_af_men_2020', 'bl_af_women_2020', 'bl_af_total_2020']\n",
      "['hisp_men_2020', 'hisp_women_2020', 'hisp_total_2020']\n",
      "['haw_pac_men_2020', 'haw_pac_women_2020', 'haw_pac_total_2020']\n",
      "['white_men_2020', 'white_women_2020', 'white_total_2020']\n",
      "['two_plus_race_men_2020', 'two_plus_race_women_2020', 'two_plus_race_total_2020']\n",
      "['unk_men_2020', 'unk_women_2020', 'unk_total_2020']\n",
      "['alien_men_2020', 'alien_women_2020', 'alien_total_2020']\n",
      "['applicants_men_2019', 'applicants_women_2019', 'applicants_total_2019']\n",
      "['admissions_men_2019', 'admission_women_2019', 'admissions_total_2019']\n",
      "['enrolled_ft_men_total_2019', 'enrolled_ft_women_total_2019', 'enrolled_ft_total_2019']\n",
      "['enrolled_pt_men_total_2019', 'enrolled_pt_women_total_2019', 'enrolled_pt_total_2019']\n",
      "['grand_total_men_2019', 'grand_total_women_2019', 'grand_total_2019']\n",
      "['am_ind_alaska_total_men_2019', 'am_ind_alaska_total_women_2019', 'am_ind_alaska_total_2019']\n",
      "['asian_men_2019', 'asian_women_2019', 'asian_total_2019']\n",
      "['bl_af_men_2019', 'bl_af_women_2019', 'bl_af_total_2019']\n",
      "['hisp_men_2019', 'hisp_women_2019', 'hisp_total_2019']\n",
      "['haw_pac_men_2019', 'haw_pac_women_2019', 'haw_pac_total_2019']\n",
      "['white_men_2019', 'white_women_2019', 'white_total_2019']\n",
      "['two_plus_race_men_2019', 'two_plus_race_women_2019', 'two_plus_race_total_2019']\n",
      "['unk_men_2019', 'unk_women_2019', 'unk_total_2019']\n",
      "['alien_men_2019', 'alien_women_2019', 'alien_total_2019']\n",
      "['applicants_men_2018', 'applicants_women_2018', 'applicants_total_2018']\n",
      "['admissions_men_2018', 'admission_women_2018', 'admissions_total_2018']\n",
      "['enrolled_ft_men_total_2018', 'enrolled_ft_women_total_2018', 'enrolled_ft_total_2018']\n",
      "['enrolled_pt_men_total_2018', 'enrolled_pt_women_total_2018', 'enrolled_pt_total_2018']\n",
      "['grand_total_men_2018', 'grand_total_women_2018', 'grand_total_2018']\n",
      "['am_ind_alaska_total_men_2018', 'am_ind_alaska_total_women_2018', 'am_ind_alaska_total_2018']\n",
      "['asian_men_2018', 'asian_women_2018', 'asian_total_2018']\n",
      "['bl_af_men_2018', 'bl_af_women_2018', 'bl_af_total_2018']\n",
      "['hisp_men_2018', 'hisp_women_2018', 'hisp_total_2018']\n",
      "['haw_pac_men_2018', 'haw_pac_women_2018', 'haw_pac_total_2018']\n",
      "['white_men_2018', 'white_women_2018', 'white_total_2018']\n",
      "['two_plus_race_men_2018', 'two_plus_race_women_2018', 'two_plus_race_total_2018']\n",
      "['unk_men_2018', 'unk_women_2018', 'unk_total_2018']\n",
      "['alien_men_2018', 'alien_women_2018', 'alien_total_2018']\n",
      "['applicants_men_2017', 'applicants_women_2017', 'applicants_total_2017']\n",
      "['admissions_men_2017', 'admission_women_2017', 'admissions_total_2017']\n",
      "['enrolled_ft_men_total_2017', 'enrolled_ft_women_total_2017', 'enrolled_ft_total_2017']\n",
      "['enrolled_pt_men_total_2017', 'enrolled_pt_women_total_2017', 'enrolled_pt_total_2017']\n",
      "['grand_total_men_2017', 'grand_total_women_2017', 'grand_total_2017']\n",
      "['am_ind_alaska_total_men_2017', 'am_ind_alaska_total_women_2017', 'am_ind_alaska_total_2017']\n",
      "['asian_men_2017', 'asian_women_2017', 'asian_total_2017']\n",
      "['bl_af_men_2017', 'bl_af_women_2017', 'bl_af_total_2017']\n",
      "['hisp_men_2017', 'hisp_women_2017', 'hisp_total_2017']\n",
      "['haw_pac_men_2017', 'haw_pac_women_2017', 'haw_pac_total_2017']\n",
      "['white_men_2017', 'white_women_2017', 'white_total_2017']\n",
      "['two_plus_race_men_2017', 'two_plus_race_women_2017', 'two_plus_race_total_2017']\n",
      "['unk_men_2017', 'unk_women_2017', 'unk_total_2017']\n",
      "['alien_men_2017', 'alien_women_2017', 'alien_total_2017']\n",
      "       unit_id                                               name  \\\n",
      "0     102669.0                          Alaska Pacific University   \n",
      "1     102553.0                     University of Alaska Anchorage   \n",
      "2     102614.0                     University of Alaska Fairbanks   \n",
      "3     102632.0                     University of Alaska Southeast   \n",
      "4     103529.0    University of Alaska System of Higher Education   \n",
      "...        ...                                                ...   \n",
      "2137  238032.0                           West Virginia University   \n",
      "2138  237905.0  West Virginia University Hospital Departments ...   \n",
      "2139  237969.0                     West Virginia Wesleyan College   \n",
      "2140  238078.0                                Wheeling University   \n",
      "2141  240727.0                              University of Wyoming   \n",
      "\n",
      "      applicants_total_2021  applicants_men_2021  applicants_women_2021  \\\n",
      "0                     504.0                120.0                  384.0   \n",
      "1                    3431.0               1460.0                 1971.0   \n",
      "2                    1402.0                636.0                  766.0   \n",
      "3                     464.0                164.0                  300.0   \n",
      "4                    1463.0                835.0                  628.0   \n",
      "...                     ...                  ...                    ...   \n",
      "2137                17074.0               7761.0                 9313.0   \n",
      "2138                 4173.0               1706.0                 2467.0   \n",
      "2139                 1766.0                903.0                  863.0   \n",
      "2140                 1277.0                806.0                  471.0   \n",
      "2141                 5645.0               2782.0                 2844.0   \n",
      "\n",
      "      admissions_total_2021  admissions_men_2021  admission_women_2021  \\\n",
      "0                     484.0                113.0                 371.0   \n",
      "1                    2369.0                994.0                1375.0   \n",
      "2                     907.0                426.0                 481.0   \n",
      "3                     261.0                 97.0                 164.0   \n",
      "4                    1158.0                617.0                 541.0   \n",
      "...                     ...                  ...                   ...   \n",
      "2137                15336.0               6855.0                8481.0   \n",
      "2138                 3001.0               1698.0                1303.0   \n",
      "2139                 1491.0                752.0                 739.0   \n",
      "2140                  997.0                618.0                 379.0   \n",
      "2141                 5463.0               2671.0                2773.0   \n",
      "\n",
      "      enrolled_men_total_2021  enrolled_women_total_2021  ...  \\\n",
      "0                         6.0                       34.0  ...   \n",
      "1                       441.0                      549.0  ...   \n",
      "2                       314.0                      364.0  ...   \n",
      "3                        62.0                       87.0  ...   \n",
      "4                         NaN                        NaN  ...   \n",
      "...                       ...                        ...  ...   \n",
      "2137                   2065.0                     2248.0  ...   \n",
      "2138                      NaN                        NaN  ...   \n",
      "2139                    148.0                      154.0  ...   \n",
      "2140                    108.0                       43.0  ...   \n",
      "2141                    733.0                      744.0  ...   \n",
      "\n",
      "      price_room_and_board_off_campus_2017  \\\n",
      "0                                      NaN   \n",
      "1                                      NaN   \n",
      "2                                      NaN   \n",
      "3                                      NaN   \n",
      "4                                      NaN   \n",
      "...                                    ...   \n",
      "2137                                   NaN   \n",
      "2138                                   NaN   \n",
      "2139                                   NaN   \n",
      "2140                                   NaN   \n",
      "2141                                   NaN   \n",
      "\n",
      "      price_other_off_campus_family_2017  \\\n",
      "0                                    NaN   \n",
      "1                                    NaN   \n",
      "2                                    NaN   \n",
      "3                                    NaN   \n",
      "4                                    NaN   \n",
      "...                                  ...   \n",
      "2137                                 NaN   \n",
      "2138                                 NaN   \n",
      "2139                                 NaN   \n",
      "2140                                 NaN   \n",
      "2141                                 NaN   \n",
      "\n",
      "      price_room_and_board_off_campus_family_2017  \\\n",
      "0                                             NaN   \n",
      "1                                             NaN   \n",
      "2                                             NaN   \n",
      "3                                             NaN   \n",
      "4                                             NaN   \n",
      "...                                           ...   \n",
      "2137                                          NaN   \n",
      "2138                                          NaN   \n",
      "2139                                          NaN   \n",
      "2140                                          NaN   \n",
      "2141                                          NaN   \n",
      "\n",
      "                                           name_alias        city  state  \\\n",
      "0                                                       Anchorage     AK   \n",
      "1                                                 UAA   Anchorage     AK   \n",
      "2                                                 UAF   Fairbanks     AK   \n",
      "3                                                          Juneau     AK   \n",
      "4                  University of Alaska System Office   Fairbanks     AK   \n",
      "...                                               ...         ...    ...   \n",
      "2137                                                   Morgantown     WV   \n",
      "2138  WVU Medicine Imaging Science Education Programs  Morgantown     WV   \n",
      "2139                                                   Buckhannon     WV   \n",
      "2140                                                     Wheeling     WV   \n",
      "2141                                               UW     Laramie     WY   \n",
      "\n",
      "        zip_code  category   latitude   longitude  \n",
      "0          99508       2.0  61.201400 -149.817502  \n",
      "1          99508       2.0  61.201400 -149.817502  \n",
      "2          99775       2.0  64.858130 -147.824759  \n",
      "3     99801-8697       2.0  58.372910 -134.178445  \n",
      "4     99775-5000      -2.0  64.858130 -147.824759  \n",
      "...          ...       ...        ...         ...  \n",
      "2137       26506       2.0  39.636600  -79.954300  \n",
      "2138  26506-8062       5.0  39.636600  -79.954300  \n",
      "2139  26201-2994       2.0  39.001871  -80.197424  \n",
      "2140       26003       2.0  40.070163  -80.647242  \n",
      "2141       82071       2.0  41.658500 -106.050700  \n",
      "\n",
      "[2142 rows x 299 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Filter US colleges based on state\n",
    "state_abbreviations = {\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA',\n",
    "    'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK',\n",
    "    'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "}\n",
    "\n",
    "years = [\"_2021\", \"_2020\", \"_2019\", \"_2018\", \"_2017\"]\n",
    "\n",
    "columns = [\n",
    "    [\"applicants_men\", \"applicants_women\", \"applicants_total\"],\n",
    "    [\"admissions_men\", \"admission_women\", \"admissions_total\"],\n",
    "    [\"enrolled_ft_men_total\", \"enrolled_ft_women_total\", \"enrolled_ft_total\"],\n",
    "    [\"enrolled_pt_men_total\", \"enrolled_pt_women_total\", \"enrolled_pt_total\"],\n",
    "    [\"grand_total_men\", \"grand_total_women\", \"grand_total\"],\n",
    "    [\"am_ind_alaska_total_men\", \"am_ind_alaska_total_women\", \"am_ind_alaska_total\"],\n",
    "    [\"asian_men\", \"asian_women\", \"asian_total\"],\n",
    "    [\"bl_af_men\", \"bl_af_women\", \"bl_af_total\"],\n",
    "    [\"hisp_men\", \"hisp_women\", \"hisp_total\"],\n",
    "    [\"haw_pac_men\", \"haw_pac_women\", \"haw_pac_total\"],\n",
    "    [\"white_men\", \"white_women\", \"white_total\"],\n",
    "    [\"two_plus_race_men\", \"two_plus_race_women\", \"two_plus_race_total\"],\n",
    "    [\"unk_men\", \"unk_women\", \"unk_total\"],\n",
    "    [\"alien_men\", \"alien_women\", \"alien_total\"]\n",
    "]\n",
    "    \n",
    "# column_men = 'hisp_men_2018'  \n",
    "# column_women = 'hisp_women_2018'\n",
    "# column_total = 'hisp_total_2018'\n",
    "\n",
    "def filter_us_colleges(df, state):\n",
    "    return df[df['state'] == state]\n",
    "\n",
    "# Helper function to calculate mean with standard deviation of 2\n",
    "def mean_within_2_std(column):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    # while True:\n",
    "    #     try:\n",
    "            \n",
    "    #     except OverflowError:\n",
    "    #         print(mean, std)\n",
    "    #         low = math.floor(mean)\n",
    "    #     if low > 0:\n",
    "    #         break\n",
    "    #     n += 1\n",
    "    low = math.floor(mean - (std/2))\n",
    "    if low < 0:\n",
    "        low = math.floor(mean)\n",
    "        high = math.ceil(mean + (std))\n",
    "    else:\n",
    "        high = math.ceil(mean + (std/2))\n",
    "    return low, high\n",
    "\n",
    "# Helper function to calculate missing values based on the conditions\n",
    "def calculate_missing_values(row, state_colleges, column):\n",
    "    men = row[column[0]]\n",
    "    women = row[column[1]]\n",
    "    total = row[column[2]]\n",
    "\n",
    "    if pd.isnull(men) and pd.isnull(women) and pd.isnull(total):\n",
    "        men_min, men_max = mean_within_2_std(state_colleges[column[0]].dropna())\n",
    "        women_min, women_max = mean_within_2_std(state_colleges[column[1]].dropna())\n",
    "        men_mean = random.randint(men_min, men_max)\n",
    "        women_mean = random.randint(women_min, women_max)\n",
    "        row[column[0]] = men_mean\n",
    "        row[column[1]]= women_mean\n",
    "        row[column[2]]= men_mean + women_mean\n",
    "\n",
    "    elif pd.isnull(men) and pd.isnull(women):\n",
    "        men_min, men_max = mean_within_2_std(state_colleges[column[0]].dropna())\n",
    "        men_mean = random.randint(men_min, men_max)\n",
    "        row[column[0]] = men_mean\n",
    "        row[column[1]]= total - men_mean\n",
    "\n",
    "    elif pd.isnull(total):\n",
    "        total_min, total_max = mean_within_2_std(state_colleges[column[2]].dropna())\n",
    "        total_mean = random.randint(total_min, total_max)\n",
    "        if pd.isnull(men):\n",
    "            row[column[0]] = total_mean - women\n",
    "        else:\n",
    "            row[column[1]] =total_mean - men\n",
    "        row[column[2]]= total_mean\n",
    "\n",
    "    elif pd.isnull(men):\n",
    "        row[column[0]] = total - women\n",
    "\n",
    "    elif pd.isnull(women):\n",
    "        row[column[1]]= total - men\n",
    "\n",
    "    return row\n",
    "\n",
    "def fill_missing_values(df, state, column):\n",
    "    state_colleges = filter_us_colleges(df, state)\n",
    "    state_colleges = state_colleges.apply(lambda row: calculate_missing_values(row, state_colleges, column), axis=1)\n",
    "    df.update(state_colleges)\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "file_path = \"static/with_missing_values/combined_with_lat_long.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "for year in years:\n",
    "    for column in columns:\n",
    "        mod_columns = [c + year for c in column]\n",
    "        print(mod_columns)\n",
    "        for state in state_abbreviations:\n",
    "            df = fill_missing_values(df, state, mod_columns)\n",
    "\n",
    "print(df)\n",
    "#  Save the filled DataFrame to a new CSV file\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# df.to_csv(f\"filled_college_data_{current_time}.csv\", index=False)\n",
    "df.to_csv(f\"complete_dataset_{current_time}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057661b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d08127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def mean_within_2_std(column):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    n = 2\n",
    "    while True:\n",
    "        low = np.floor(mean - (std/n)).item()\n",
    "        if low > 0:\n",
    "            break\n",
    "        n += 1\n",
    "    high = np.ceil(mean + (std/n)).item()\n",
    "    return low, high\n",
    "\n",
    "def fill_missing_values(df, columns):\n",
    "    for column in columns:\n",
    "        while df[column].isnull().any():\n",
    "            non_null_column = df[column].dropna()\n",
    "            for index, value in df[column].iteritems():\n",
    "                if pd.isnull(value):\n",
    "                    low, high = mean_within_2_std(non_null_column)\n",
    "                    filled_value = random.randint(low, high)\n",
    "                    df.at[index, column] = filled_value\n",
    "                    non_null_column = df[column].dropna()\n",
    "    return df\n",
    "\n",
    "file_path = r\"C:\\\\College_Compass_backend\\\\college-compass-backend-flask\\\\static\\\\with_missing_values\\\\combined_with_lat_long.csv\"\n",
    "df = pd.read_csv('complete_dataset.csv')\n",
    "\n",
    "# Replace 'column_name_1', 'column_name_2', ... with the column names you want to fill missing values for\n",
    "columns_to_fill = [\n",
    "    'price_in_dist_on_campus_2021',\n",
    "    'price_in_st_on_campus_2021',\n",
    "    'price_out_st_on_campus_2021',\n",
    "    'price_in_dist_off_campus_2021',\n",
    "    'price_in_st_off_campus_2021',\n",
    "    'price_out_st_off_campus_2021',\n",
    "    'price_in_dist_off_campus_family_2021',\n",
    "    'price_in_st_off_campus_family_2021',\n",
    "    'price_out_st_off_campus_family_2021',\n",
    "    'price_other_off_campus_2021',\n",
    "    'price_room_and_board_off_campus_2021',\n",
    "    'price_other_off_campus_family_2021',\n",
    "    'price_room_and_board_off_campus_family_2021'\n",
    "]\n",
    "\n",
    "df = fill_missing_values(df, columns_to_fill)\n",
    "\n",
    "# Save the filled DataFrame to a new CSV file\n",
    "# output_path = r'C:\\College_Compass_backend\\college-compass-backend-flask\\static\\filled_values.csv'\n",
    "output_path = 'complete_dataset.csv'\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
